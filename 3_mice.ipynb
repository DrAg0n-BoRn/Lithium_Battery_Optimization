{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Multiple Imputation by Chained Equations (MICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import miceforest as mf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "\n",
    "from paths import ENGINEERED_CSV_PATH, MICE_BASE_DIR, MICE_IMPUTED_METRICS_DIR, IMPUTED_DATASETS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "df_full = pd.read_csv(ENGINEERED_CSV_PATH, encoding='utf-8')\n",
    "df_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Apply MICE Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMPUTED_DATASETS = 1\n",
    "ITERATIONS = 20\n",
    "\n",
    "# Initialize the imputation kernel\n",
    "kernel = mf.ImputationKernel(\n",
    "    data=df_full,\n",
    "    num_datasets=IMPUTED_DATASETS,  # Number of imputed datasets\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Perform MICE with N iterations per dataset\n",
    "kernel.mice(ITERATIONS)\n",
    "\n",
    "# Retrieve the imputed datasets \n",
    "imputed_datasets = [kernel.complete_data(dataset=i) for i in range(IMPUTED_DATASETS)]\n",
    "\n",
    "# Ensure indexes match\n",
    "for i, imputed_df in enumerate(imputed_datasets, start=1):\n",
    "    assert imputed_df.shape[0] == df_full.shape[0], f\"Row count mismatch in dataset {i}\"\n",
    "    assert all(imputed_df.index == df_full.index), f\"Index mismatch in dataset {i}\"\n",
    "print(\"All imputed datasets match the original DataFrame indexes.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Save Imputed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save each imputed dataset with a unique name\n",
    "for i, imputed_df in enumerate(imputed_datasets, start=1):\n",
    "    if i < 10:\n",
    "        file_name = f\"imputed_0{i}.csv\"\n",
    "    else:\n",
    "        file_name = f\"imputed_{i}.csv\"\n",
    "    output_path = os.path.join(IMPUTED_DATASETS_DIR, file_name)\n",
    "    imputed_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved {file_name} with shape {imputed_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Get metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get feature names that had missing values before imputation\n",
    "def get_na_feature_names(df: pd.DataFrame):\n",
    "    return [col for col in df.columns if df[col].isna().any()]\n",
    "\n",
    "#Convergence diagnostic\n",
    "def get_convergence_diagnostic(kernel: mf.ImputationKernel, feature_names: list[str], iterations_cap: int=ITERATIONS):\n",
    "    for dataset_id in range(kernel.num_datasets):\n",
    "        #Check directory for current dataset\n",
    "        dataset_file_dir = f\"Convergence Metrics {dataset_id + 1}\"\n",
    "        save_dir = os.path.join(MICE_BASE_DIR, dataset_file_dir)\n",
    "        if not os.path.isdir(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        for feature_name in feature_names:\n",
    "            means_per_iteration = []\n",
    "            for iteration in range(iterations_cap):\n",
    "                current_imputed = kernel.complete_data(dataset=dataset_id, iteration=iteration)\n",
    "                means_per_iteration.append(np.mean(current_imputed[feature_name]))\n",
    "\n",
    "            plt.plot(means_per_iteration, marker='o')\n",
    "            plt.xlabel(\"Iteration\")\n",
    "            plt.ylabel(\"Mean of Imputed Values\")\n",
    "            plt.title(f\"Mean Convergence for '{feature_name}'\")\n",
    "            \n",
    "            # Adjust plot display for the X axis\n",
    "            _ticks = np.arange(iterations_cap)\n",
    "            _labels = np.arange(1, iterations_cap + 1)\n",
    "            plt.xticks(ticks=_ticks, labels=_labels)\n",
    "            \n",
    "            save_path = os.path.join(save_dir, feature_name + \".png\")\n",
    "            plt.savefig(save_path, bbox_inches='tight')\n",
    "            plt.close()\n",
    "            \n",
    "        print(f\"{dataset_file_dir} completed.\")\n",
    "\n",
    "# Imputed distributions\n",
    "def get_imputed_distributions(kernel: mf.ImputationKernel, feature_names: Union[list[str], None]=None, individual_plots: bool=True):\n",
    "    ''' \n",
    "    It works using miceforest's authors implementation of the method `.plot_imputed_distributions()`.\n",
    "    \n",
    "    Set individual_plots=False to save a single image with all feature distributions.\n",
    "    '''\n",
    "    # Styling parameters\n",
    "    legend_kwargs = {'frameon': True, 'facecolor': 'white', 'framealpha': 0.8}\n",
    "    label_font = {'size': 14, 'weight': 'bold'}\n",
    "\n",
    "    def _process_figure(fig, filename):\n",
    "        \"\"\"Helper function to add labels and legends to a figure\"\"\"\n",
    "        for ax in fig.axes:\n",
    "            # Set axis labels\n",
    "            ax.set_xlabel('Value', **label_font)\n",
    "            ax.set_ylabel('Density', **label_font)\n",
    "            \n",
    "            # Add legend based on line colors\n",
    "            lines = ax.get_lines()\n",
    "            if len(lines) >= 1:\n",
    "                lines[0].set_label('Original Data')\n",
    "                if len(lines) > 1:\n",
    "                    lines[1].set_label('Imputed Data')\n",
    "                ax.legend(**legend_kwargs)\n",
    "                \n",
    "        # Adjust layout and save\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(\n",
    "            os.path.join(MICE_IMPUTED_METRICS_DIR, filename),\n",
    "            dpi=300,\n",
    "            bbox_inches='tight',\n",
    "            pad_inches=0.2\n",
    "        )\n",
    "        plt.close(fig)\n",
    "\n",
    "    if individual_plots and feature_names:\n",
    "        # Generate individual plots per feature\n",
    "        for feature in feature_names:\n",
    "            fig = kernel.plot_imputed_distributions(variables=[feature])\n",
    "            _process_figure(fig, f\"{feature}.png\")\n",
    "    else:\n",
    "        # Generate combined plot\n",
    "        fig = kernel.plot_imputed_distributions(variables=feature_names)\n",
    "        _process_figure(fig, \"Combined_Distributions.png\")\n",
    "    \n",
    "    print(\"Imputed distributions saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run functions\n",
    "na_feature_names = get_na_feature_names(df_full)\n",
    "get_convergence_diagnostic(kernel=kernel, feature_names=na_feature_names)\n",
    "get_imputed_distributions(kernel=kernel, feature_names=na_feature_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thyroid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
